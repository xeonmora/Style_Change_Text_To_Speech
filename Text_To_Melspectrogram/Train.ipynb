{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTgI9xWN9BLr",
    "outputId": "124c07f7-0f57-48fe-9c84-00350a492727"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15\n",
    "!pip install torch==1.6\n",
    "!pip install torch-stft\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cjVSbMHCtFK"
   },
   "source": [
    "### LJSpeech Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDNvSP9S-VGE",
    "outputId": "daf420df-3c44-446e-caa9-712898571bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-21 17:56:20--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
      "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
      "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2748572632 (2.6G) [application/octet-stream]\n",
      "Saving to: ‘LJSpeech-1.1.tar.bz2’\n",
      "\n",
      "LJSpeech-1.1.tar.bz 100%[===================>]   2.56G  36.4MB/s    in 58s     \n",
      "\n",
      "2021-05-21 17:57:18 (45.4 MB/s) - ‘LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Slxgc6Zm-kCt",
    "outputId": "58e0da1e-12c9-4568-e7a5-37db0d95dd63",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tar -jxvf LJSpeech-1.1.tar.bz2\n",
    "!mv LJSpeech-1.1  ljs_dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4RvV4_zAs8J",
    "outputId": "8b8106be-3b31-4913-8e67-7266a828f491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pZ3wd3mzNndqjCcOOs72YkDRFt8pzbH2\n",
      "To: /content/filelists.zip\n",
      "\r",
      "  0% 0.00/603k [00:00<?, ?B/s]\r",
      "100% 603k/603k [00:00<00:00, 9.56MB/s]\n",
      "Archive:  filelists.zip\n",
      "   creating: filelists/\n",
      "  inflating: filelists/ljs_audio_text_train_filelist.txt  \n",
      "  inflating: filelists/ljs_audio_text_val_filelist.txt  \n",
      "  inflating: filelists/ljs_audio_text_test_filelist.txt  \n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1pZ3wd3mzNndqjCcOOs72YkDRFt8pzbH2\n",
    "!unzip filelists.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bq6m69FHCbdf",
    "outputId": "0a635c59-b7bb-4c48-ebb3-99cf55521a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hWvZh6uf63sTo-LoHFf6EVxfrIPQRBHw\n",
      "To: /content/text.zip\n",
      "\r",
      "  0% 0.00/12.8k [00:00<?, ?B/s]\r",
      "100% 12.8k/12.8k [00:00<00:00, 11.3MB/s]\n",
      "Archive:  text.zip\n",
      "   creating: text/\n",
      "  inflating: text/LICENSE            \n",
      "  inflating: text/__init__.py        \n",
      "  inflating: text/cleaners.py        \n",
      "  inflating: text/cmudict.py         \n",
      "  inflating: text/numbers.py         \n",
      "  inflating: text/symbols.py         \n",
      "   creating: text/__pycache__/\n",
      "  inflating: text/__pycache__/__init__.cpython-37.pyc  \n",
      "  inflating: text/__pycache__/cleaners.cpython-37.pyc  \n",
      "  inflating: text/__pycache__/numbers.cpython-37.pyc  \n",
      "  inflating: text/__pycache__/symbols.cpython-37.pyc  \n",
      "  inflating: text/__pycache__/cmudict.cpython-37.pyc  \n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1hWvZh6uf63sTo-LoHFf6EVxfrIPQRBHw\n",
    "!unzip text.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-yQBYwHByxL",
    "outputId": "75143da4-57dd-4e3c-d990-ab00b8d5db33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Oawff7hwoUkPWFQTgL2Er8FQEifNV5ih\n",
      "To: /content/files.zip\n",
      "\r",
      "  0% 0.00/3.73k [00:00<?, ?B/s]\r",
      "100% 3.73k/3.73k [00:00<00:00, 6.16MB/s]\n",
      "Archive:  files.zip\n",
      "replace audio_processing.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: audio_processing.py     \n",
      "replace hparams.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: hparams.py              \n",
      "replace layers.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: layers.py               \n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1Oawff7hwoUkPWFQTgL2Er8FQEifNV5ih\n",
    "!unzip -j files.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LXjDui-VAzvb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.io.wavfile import read\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import layers\n",
    "from hparams import create_hparams\n",
    "from layers import ConvNorm, LinearNorm\n",
    "from text import text_to_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9DT1jMeCnhx"
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T-1Na8ORA09c"
   },
   "outputs": [],
   "source": [
    "def get_mask_from_lengths(lengths):\n",
    "    max_len = torch.max(lengths).item()\n",
    "    ids = torch.arange(0, max_len, out=torch.cuda.LongTensor(max_len))\n",
    "    mask = (ids < lengths.unsqueeze(1)).bool()\n",
    "    return mask\n",
    "\n",
    "\n",
    "def load_wav_to_torch(full_path):\n",
    "    sampling_rate, data = read(full_path)\n",
    "    return torch.FloatTensor(data.astype(np.float32)), sampling_rate\n",
    "\n",
    "\n",
    "def load_filepaths_and_text(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "    return filepaths_and_text\n",
    "\n",
    "\n",
    "def to_gpu(x):\n",
    "    x = x.contiguous()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda(non_blocking=True)\n",
    "    return torch.autograd.Variable(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIZP0yPnCwVY"
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-OyuE2T8Cxix"
   },
   "outputs": [],
   "source": [
    "class TextMelLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, audiopaths_and_text, hparams):\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(audiopaths_and_text)\n",
    "        self.text_cleaners = hparams.text_cleaners\n",
    "        self.max_wav_value = hparams.max_wav_value\n",
    "        self.sampling_rate = hparams.sampling_rate\n",
    "        self.load_mel_from_disk = hparams.load_mel_from_disk\n",
    "        self.stft = layers.TacotronSTFT(\n",
    "            hparams.filter_length, hparams.hop_length, hparams.win_length,\n",
    "            hparams.n_mel_channels, hparams.sampling_rate, hparams.mel_fmin,\n",
    "            hparams.mel_fmax)\n",
    "        random.seed(hparams.seed)\n",
    "        random.shuffle(self.audiopaths_and_text)\n",
    "\n",
    "    def get_mel_text_pair(self, audiopath_and_text):\n",
    "        # separate filename and text\n",
    "        audiopath, text = audiopath_and_text[0], audiopath_and_text[1]\n",
    "        text = self.get_text(text)\n",
    "        mel = self.get_mel(audiopath)\n",
    "        return (text, mel)\n",
    "\n",
    "    def get_mel(self, filename):\n",
    "        if not self.load_mel_from_disk:\n",
    "            audio, sampling_rate = load_wav_to_torch(filename)\n",
    "            if sampling_rate != self.stft.sampling_rate:\n",
    "                raise ValueError(\"{} {} SR doesn't match target {} SR\".format(\n",
    "                    sampling_rate, self.stft.sampling_rate))\n",
    "            audio_norm = audio / self.max_wav_value\n",
    "            audio_norm = audio_norm.unsqueeze(0)\n",
    "            audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
    "            melspec = self.stft.mel_spectrogram(audio_norm)\n",
    "            melspec = torch.squeeze(melspec, 0)\n",
    "        else:\n",
    "            melspec = torch.from_numpy(np.load(filename))\n",
    "            assert melspec.size(0) == self.stft.n_mel_channels, (\n",
    "                'Mel dimension mismatch: given {}, expected {}'.format(\n",
    "                    melspec.size(0), self.stft.n_mel_channels))\n",
    "\n",
    "        return melspec\n",
    "\n",
    "    def get_text(self, text):\n",
    "        text_norm = torch.IntTensor(text_to_sequence(text, self.text_cleaners))\n",
    "        return text_norm\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.get_mel_text_pair(self.audiopaths_and_text[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audiopaths_and_text)\n",
    "\n",
    "\n",
    "class TextMelCollate():\n",
    "    def __init__(self, n_frames_per_step):\n",
    "        self.n_frames_per_step = n_frames_per_step\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        input_lengths, ids_sorted_decreasing = torch.sort(\n",
    "            torch.LongTensor([len(x[0]) for x in batch]),\n",
    "            dim=0, descending=True)\n",
    "        max_input_len = input_lengths[0]\n",
    "\n",
    "        text_padded = torch.LongTensor(len(batch), max_input_len)\n",
    "        text_padded.zero_()\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            text = batch[ids_sorted_decreasing[i]][0]\n",
    "            text_padded[i, :text.size(0)] = text\n",
    "\n",
    "        # Right zero-pad mel-spec\n",
    "        num_mels = batch[0][1].size(0)\n",
    "        max_target_len = max([x[1].size(1) for x in batch])\n",
    "        if max_target_len % self.n_frames_per_step != 0:\n",
    "            max_target_len += self.n_frames_per_step - max_target_len % self.n_frames_per_step\n",
    "            assert max_target_len % self.n_frames_per_step == 0\n",
    "\n",
    "        # include mel padded and gate padded\n",
    "        mel_padded = torch.FloatTensor(len(batch), num_mels, max_target_len)\n",
    "        mel_padded.zero_()\n",
    "        gate_padded = torch.FloatTensor(len(batch), max_target_len)\n",
    "        gate_padded.zero_()\n",
    "        output_lengths = torch.LongTensor(len(batch))\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            mel = batch[ids_sorted_decreasing[i]][1]\n",
    "            mel_padded[i, :, :mel.size(1)] = mel\n",
    "            gate_padded[i, mel.size(1) - 1:] = 1\n",
    "            output_lengths[i] = mel.size(1)\n",
    "\n",
    "        return text_padded, input_lengths, mel_padded, gate_padded, \\\n",
    "               output_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e91waBZaC2O2"
   },
   "outputs": [],
   "source": [
    "def prepare_dataloaders(hparams):\n",
    "    # Get data, data loaders and collate function ready\n",
    "    trainset = TextMelLoader(hparams.training_files, hparams)\n",
    "    valset = TextMelLoader(hparams.validation_files, hparams)\n",
    "    collate_fn = TextMelCollate(hparams.n_frames_per_step)\n",
    "\n",
    "    if hparams.distributed_run:\n",
    "        train_sampler = DistributedSampler(trainset)\n",
    "        shuffle = False\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        shuffle = True\n",
    "\n",
    "    train_loader = DataLoader(trainset, num_workers=1, shuffle=shuffle,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=hparams.batch_size, pin_memory=False,\n",
    "                              drop_last=True, collate_fn=collate_fn)\n",
    "    return train_loader, valset, collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XaYgHA7C7Zb",
    "outputId": "c2eb7229-e0c6-4e53-84f5-1ebd154ffb18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = create_hparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxDzege_DCST"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbUeQ4rYC4Uy"
   },
   "source": [
    "### Location layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "U1_d9N5tC2D9"
   },
   "outputs": [],
   "source": [
    "class LocationLayer(nn.Module):\n",
    "    def __init__(self, attention_n_filters, attention_kernel_size,\n",
    "                 attention_dim):\n",
    "        super(LocationLayer, self).__init__()\n",
    "        padding = int((attention_kernel_size - 1) / 2)\n",
    "        self.location_conv = ConvNorm(2, attention_n_filters,\n",
    "                                      kernel_size=attention_kernel_size,\n",
    "                                      padding=padding, bias=False, stride=1,\n",
    "                                      dilation=1)\n",
    "        self.location_dense = LinearNorm(attention_n_filters, attention_dim,\n",
    "                                         bias=False, w_init_gain='tanh')\n",
    "\n",
    "    def forward(self, attention_weights_cat):\n",
    "        processed_attention = self.location_conv(attention_weights_cat)\n",
    "        processed_attention = processed_attention.transpose(1, 2)\n",
    "        processed_attention = self.location_dense(processed_attention)\n",
    "        return processed_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqR8ZOJLC8qI"
   },
   "source": [
    "### Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZYi7UoJOC-wt"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, attention_rnn_dim, embedding_dim, attention_dim,\n",
    "                 attention_location_n_filters, attention_location_kernel_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.query_layer = LinearNorm(attention_rnn_dim, attention_dim,\n",
    "                                      bias=False, w_init_gain='tanh')\n",
    "        self.memory_layer = LinearNorm(embedding_dim, attention_dim, bias=False,\n",
    "                                       w_init_gain='tanh')\n",
    "        self.v = LinearNorm(attention_dim, 1, bias=False)\n",
    "        self.location_layer = LocationLayer(attention_location_n_filters,\n",
    "                                            attention_location_kernel_size,\n",
    "                                            attention_dim)\n",
    "        self.score_mask_value = -float(\"inf\")\n",
    "\n",
    "    def get_alignment_energies(self, query, processed_memory,\n",
    "                               attention_weights_cat):\n",
    "        processed_query = self.query_layer(query.unsqueeze(1))\n",
    "        processed_attention_weights = self.location_layer(attention_weights_cat)\n",
    "        energies = self.v(torch.tanh(\n",
    "            processed_query + processed_attention_weights + processed_memory))\n",
    "\n",
    "        energies = energies.squeeze(-1)\n",
    "        return energies\n",
    "\n",
    "    def forward(self, attention_hidden_state, memory, processed_memory,\n",
    "                attention_weights_cat, mask):\n",
    "        alignment = self.get_alignment_energies(\n",
    "            attention_hidden_state, processed_memory, attention_weights_cat)\n",
    "\n",
    "        if mask is not None:\n",
    "            alignment.data.masked_fill_(mask, self.score_mask_value)\n",
    "\n",
    "        attention_weights = F.softmax(alignment, dim=1)\n",
    "        attention_context = torch.bmm(attention_weights.unsqueeze(1), memory)\n",
    "        attention_context = attention_context.squeeze(1)\n",
    "\n",
    "        return attention_context, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZYkk0TSDBJ2"
   },
   "source": [
    "### PreNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WclXrba-DCyX"
   },
   "outputs": [],
   "source": [
    "class Prenet(nn.Module):\n",
    "    def __init__(self, in_dim, sizes):\n",
    "        super(Prenet, self).__init__()\n",
    "        in_sizes = [in_dim] + sizes[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [LinearNorm(in_size, out_size, bias=False)\n",
    "             for (in_size, out_size) in zip(in_sizes, sizes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.layers:\n",
    "            x = F.dropout(F.relu(linear(x)), p=0.5, training=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R90tFAkCDFy0"
   },
   "source": [
    "### PostNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "utpZR5J1DH1U"
   },
   "outputs": [],
   "source": [
    "class Postnet(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Postnet, self).__init__()\n",
    "        self.convolutions = nn.ModuleList()\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(hparams.n_mel_channels, hparams.postnet_embedding_dim,\n",
    "                         kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                         padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='tanh'),\n",
    "                nn.BatchNorm1d(hparams.postnet_embedding_dim))\n",
    "        )\n",
    "\n",
    "        for i in range(1, hparams.postnet_n_convolutions - 1):\n",
    "            self.convolutions.append(\n",
    "                nn.Sequential(\n",
    "                    ConvNorm(hparams.postnet_embedding_dim,\n",
    "                             hparams.postnet_embedding_dim,\n",
    "                             kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                             padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                             dilation=1, w_init_gain='tanh'),\n",
    "                    nn.BatchNorm1d(hparams.postnet_embedding_dim))\n",
    "            )\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(hparams.postnet_embedding_dim, hparams.n_mel_channels,\n",
    "                         kernel_size=hparams.postnet_kernel_size, stride=1,\n",
    "                         padding=int((hparams.postnet_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='linear'),\n",
    "                nn.BatchNorm1d(hparams.n_mel_channels))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.convolutions) - 1):\n",
    "            x = F.dropout(torch.tanh(self.convolutions[i](x)), 0.5, self.training)\n",
    "        x = F.dropout(self.convolutions[-1](x), 0.5, self.training)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HgGkSYtDJ7G"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OJYkMkFIDMA3"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        convolutions = []\n",
    "        for _ in range(hparams.encoder_n_convolutions):\n",
    "            conv_layer = nn.Sequential(\n",
    "                ConvNorm(hparams.encoder_embedding_dim,\n",
    "                         hparams.encoder_embedding_dim,\n",
    "                         kernel_size=hparams.encoder_kernel_size, stride=1,\n",
    "                         padding=int((hparams.encoder_kernel_size - 1) / 2),\n",
    "                         dilation=1, w_init_gain='relu'),\n",
    "                nn.BatchNorm1d(hparams.encoder_embedding_dim))\n",
    "            convolutions.append(conv_layer)\n",
    "        self.convolutions = nn.ModuleList(convolutions)\n",
    "\n",
    "        self.lstm = nn.LSTM(hparams.encoder_embedding_dim,\n",
    "                            int(hparams.encoder_embedding_dim / 2), 1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, input_lengths):\n",
    "        for conv in self.convolutions:\n",
    "            x = F.dropout(F.relu(conv(x)), 0.5, self.training)\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # pytorch tensor are not reversible, hence the conversion\n",
    "        input_lengths = input_lengths.cpu().numpy()\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, input_lengths, batch_first=True)\n",
    "\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def inference(self, x):\n",
    "        for conv in self.convolutions:\n",
    "            x = F.dropout(F.relu(conv(x)), 0.5, self.training)\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYC9jx1yDO_p"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HPhr2mbcDQZQ"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step = hparams.n_frames_per_step\n",
    "        self.encoder_embedding_dim = hparams.encoder_embedding_dim\n",
    "        self.attention_rnn_dim = hparams.attention_rnn_dim\n",
    "        self.decoder_rnn_dim = hparams.decoder_rnn_dim\n",
    "        self.prenet_dim = hparams.prenet_dim\n",
    "        self.max_decoder_steps = hparams.max_decoder_steps\n",
    "        self.gate_threshold = hparams.gate_threshold\n",
    "        self.p_attention_dropout = hparams.p_attention_dropout\n",
    "        self.p_decoder_dropout = hparams.p_decoder_dropout\n",
    "\n",
    "        self.prenet = Prenet(\n",
    "            hparams.n_mel_channels * hparams.n_frames_per_step,\n",
    "            [hparams.prenet_dim, hparams.prenet_dim])\n",
    "\n",
    "        self.attention_rnn = nn.LSTMCell(\n",
    "            hparams.prenet_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.attention_rnn_dim)\n",
    "\n",
    "        self.attention_layer = Attention(\n",
    "            hparams.attention_rnn_dim, hparams.encoder_embedding_dim,\n",
    "            hparams.attention_dim, hparams.attention_location_n_filters,\n",
    "            hparams.attention_location_kernel_size)\n",
    "\n",
    "        self.decoder_rnn = nn.LSTMCell(\n",
    "            hparams.attention_rnn_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.decoder_rnn_dim, 1)\n",
    "\n",
    "        self.linear_projection = LinearNorm(\n",
    "            hparams.decoder_rnn_dim + hparams.encoder_embedding_dim,\n",
    "            hparams.n_mel_channels * hparams.n_frames_per_step)\n",
    "\n",
    "        self.gate_layer = LinearNorm(\n",
    "            hparams.decoder_rnn_dim + hparams.encoder_embedding_dim, 1,\n",
    "            bias=True, w_init_gain='sigmoid')\n",
    "\n",
    "    def get_go_frame(self, memory):\n",
    "        B = memory.size(0)\n",
    "        decoder_input = Variable(memory.data.new(\n",
    "            B, self.n_mel_channels * self.n_frames_per_step).zero_())\n",
    "        return decoder_input\n",
    "\n",
    "    def initialize_decoder_states(self, memory, mask):\n",
    "        B = memory.size(0)\n",
    "        MAX_TIME = memory.size(1)\n",
    "\n",
    "        self.attention_hidden = Variable(memory.data.new(\n",
    "            B, self.attention_rnn_dim).zero_())\n",
    "        self.attention_cell = Variable(memory.data.new(\n",
    "            B, self.attention_rnn_dim).zero_())\n",
    "\n",
    "        self.decoder_hidden = Variable(memory.data.new(\n",
    "            B, self.decoder_rnn_dim).zero_())\n",
    "        self.decoder_cell = Variable(memory.data.new(\n",
    "            B, self.decoder_rnn_dim).zero_())\n",
    "\n",
    "        self.attention_weights = Variable(memory.data.new(\n",
    "            B, MAX_TIME).zero_())\n",
    "        self.attention_weights_cum = Variable(memory.data.new(\n",
    "            B, MAX_TIME).zero_())\n",
    "        self.attention_context = Variable(memory.data.new(\n",
    "            B, self.encoder_embedding_dim).zero_())\n",
    "\n",
    "        self.memory = memory\n",
    "        self.processed_memory = self.attention_layer.memory_layer(memory)\n",
    "        self.mask = mask\n",
    "\n",
    "    def parse_decoder_inputs(self, decoder_inputs):\n",
    "        # (B, n_mel_channels, T_out) -> (B, T_out, n_mel_channels)\n",
    "        decoder_inputs = decoder_inputs.transpose(1, 2)\n",
    "        decoder_inputs = decoder_inputs.view(\n",
    "            decoder_inputs.size(0),\n",
    "            int(decoder_inputs.size(1) / self.n_frames_per_step), -1)\n",
    "        # (B, T_out, n_mel_channels) -> (T_out, B, n_mel_channels)\n",
    "        decoder_inputs = decoder_inputs.transpose(0, 1)\n",
    "        return decoder_inputs\n",
    "\n",
    "    def parse_decoder_outputs(self, mel_outputs, gate_outputs, alignments):\n",
    "        # (T_out, B) -> (B, T_out)\n",
    "        alignments = torch.stack(alignments).transpose(0, 1)\n",
    "        # (T_out, B) -> (B, T_out)\n",
    "        gate_outputs = torch.stack(gate_outputs).transpose(0, 1)\n",
    "        gate_outputs = gate_outputs.contiguous()\n",
    "        # (T_out, B, n_mel_channels) -> (B, T_out, n_mel_channels)\n",
    "        mel_outputs = torch.stack(mel_outputs).transpose(0, 1).contiguous()\n",
    "        # decouple frames per step\n",
    "        mel_outputs = mel_outputs.view(\n",
    "            mel_outputs.size(0), -1, self.n_mel_channels)\n",
    "        # (B, T_out, n_mel_channels) -> (B, n_mel_channels, T_out)\n",
    "        mel_outputs = mel_outputs.transpose(1, 2)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments\n",
    "\n",
    "    def decode(self, decoder_input):\n",
    "        cell_input = torch.cat((decoder_input, self.attention_context), -1)\n",
    "        self.attention_hidden, self.attention_cell = self.attention_rnn(\n",
    "            cell_input, (self.attention_hidden, self.attention_cell))\n",
    "        self.attention_hidden = F.dropout(\n",
    "            self.attention_hidden, self.p_attention_dropout, self.training)\n",
    "\n",
    "        attention_weights_cat = torch.cat(\n",
    "            (self.attention_weights.unsqueeze(1),\n",
    "             self.attention_weights_cum.unsqueeze(1)), dim=1)\n",
    "        self.attention_context, self.attention_weights = self.attention_layer(\n",
    "            self.attention_hidden, self.memory, self.processed_memory,\n",
    "            attention_weights_cat, self.mask)\n",
    "\n",
    "        self.attention_weights_cum += self.attention_weights\n",
    "        decoder_input = torch.cat(\n",
    "            (self.attention_hidden, self.attention_context), -1)\n",
    "        self.decoder_hidden, self.decoder_cell = self.decoder_rnn(\n",
    "            decoder_input, (self.decoder_hidden, self.decoder_cell))\n",
    "        self.decoder_hidden = F.dropout(\n",
    "            self.decoder_hidden, self.p_decoder_dropout, self.training)\n",
    "\n",
    "        decoder_hidden_attention_context = torch.cat(\n",
    "            (self.decoder_hidden, self.attention_context), dim=1)\n",
    "        decoder_output = self.linear_projection(\n",
    "            decoder_hidden_attention_context)\n",
    "\n",
    "        gate_prediction = self.gate_layer(decoder_hidden_attention_context)\n",
    "        return decoder_output, gate_prediction, self.attention_weights\n",
    "\n",
    "    def forward(self, memory, decoder_inputs, memory_lengths):\n",
    "        decoder_input = self.get_go_frame(memory).unsqueeze(0)\n",
    "        decoder_inputs = self.parse_decoder_inputs(decoder_inputs)\n",
    "        decoder_inputs = torch.cat((decoder_input, decoder_inputs), dim=0)\n",
    "        decoder_inputs = self.prenet(decoder_inputs)\n",
    "\n",
    "        self.initialize_decoder_states(\n",
    "            memory, mask=~get_mask_from_lengths(memory_lengths))\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = [], [], []\n",
    "        while len(mel_outputs) < decoder_inputs.size(0) - 1:\n",
    "            decoder_input = decoder_inputs[len(mel_outputs)]\n",
    "            mel_output, gate_output, attention_weights = self.decode(\n",
    "                decoder_input)\n",
    "            mel_outputs += [mel_output.squeeze(1)]\n",
    "            gate_outputs += [gate_output.squeeze(1)]\n",
    "            alignments += [attention_weights]\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs(\n",
    "            mel_outputs, gate_outputs, alignments)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments\n",
    "\n",
    "    def inference(self, memory):\n",
    "        decoder_input = self.get_go_frame(memory)\n",
    "\n",
    "        self.initialize_decoder_states(memory, mask=None)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = [], [], []\n",
    "        while True:\n",
    "            decoder_input = self.prenet(decoder_input)\n",
    "            mel_output, gate_output, alignment = self.decode(decoder_input)\n",
    "\n",
    "            mel_outputs += [mel_output.squeeze(1)]\n",
    "            gate_outputs += [gate_output]\n",
    "            alignments += [alignment]\n",
    "\n",
    "            if torch.sigmoid(gate_output.data) > self.gate_threshold:\n",
    "                break\n",
    "            elif len(mel_outputs) == self.max_decoder_steps:\n",
    "                print(\"Warning! Reached max decoder steps\")\n",
    "                break\n",
    "\n",
    "            decoder_input = mel_output\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.parse_decoder_outputs(\n",
    "            mel_outputs, gate_outputs, alignments)\n",
    "\n",
    "        return mel_outputs, gate_outputs, alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBCHjRmbDTmC"
   },
   "source": [
    "### Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0-7ZCbkNDWnj"
   },
   "outputs": [],
   "source": [
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.mask_padding = hparams.mask_padding\n",
    "        self.fp16_run = hparams.fp16_run\n",
    "        self.n_mel_channels = hparams.n_mel_channels\n",
    "        self.n_frames_per_step = hparams.n_frames_per_step\n",
    "        self.embedding = nn.Embedding(\n",
    "            hparams.n_symbols, hparams.symbols_embedding_dim)\n",
    "        std = sqrt(2.0 / (hparams.n_symbols + hparams.symbols_embedding_dim))\n",
    "        val = sqrt(3.0) * std  # uniform bounds for std\n",
    "        self.embedding.weight.data.uniform_(-val, val)\n",
    "        self.encoder = Encoder(hparams)\n",
    "        self.decoder = Decoder(hparams)\n",
    "        self.postnet = Postnet(hparams)\n",
    "\n",
    "    def parse_batch(self, batch):\n",
    "        text_padded, input_lengths, mel_padded, gate_padded, \\\n",
    "        output_lengths = batch\n",
    "        text_padded = to_gpu(text_padded).long()\n",
    "        input_lengths = to_gpu(input_lengths).long()\n",
    "        max_len = torch.max(input_lengths.data).item()\n",
    "        mel_padded = to_gpu(mel_padded).float()\n",
    "        gate_padded = to_gpu(gate_padded).float()\n",
    "        output_lengths = to_gpu(output_lengths).long()\n",
    "\n",
    "        return (\n",
    "            (text_padded, input_lengths, mel_padded, max_len, output_lengths),\n",
    "            (mel_padded, gate_padded))\n",
    "\n",
    "    def parse_output(self, outputs, output_lengths=None):\n",
    "        if self.mask_padding and output_lengths is not None:\n",
    "            mask = ~get_mask_from_lengths(output_lengths)\n",
    "            mask = mask.expand(self.n_mel_channels, mask.size(0), mask.size(1))\n",
    "            mask = mask.permute(1, 0, 2)\n",
    "\n",
    "            outputs[0].data.masked_fill_(mask, 0.0)\n",
    "            outputs[1].data.masked_fill_(mask, 0.0)\n",
    "            outputs[2].data.masked_fill_(mask[:, 0, :], 1e3)  # gate energies\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        text_inputs, text_lengths, mels, max_len, output_lengths = inputs\n",
    "        text_lengths, output_lengths = text_lengths.data, output_lengths.data\n",
    "\n",
    "        embedded_inputs = self.embedding(text_inputs).transpose(1, 2)\n",
    "\n",
    "        encoder_outputs = self.encoder(embedded_inputs, text_lengths)\n",
    "\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder(\n",
    "            encoder_outputs, mels, memory_lengths=text_lengths)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        return self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments],\n",
    "            output_lengths)\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        embedded_inputs = self.embedding(inputs).transpose(1, 2)\n",
    "        encoder_outputs = self.encoder.inference(embedded_inputs)\n",
    "        mel_outputs, gate_outputs, alignments = self.decoder.inference(\n",
    "            encoder_outputs)\n",
    "\n",
    "        mel_outputs_postnet = self.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs + mel_outputs_postnet\n",
    "\n",
    "        outputs = self.parse_output(\n",
    "            [mel_outputs, mel_outputs_postnet, gate_outputs, alignments])\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l36Htu3DIT0"
   },
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "UDGZ0lMEC8Jc"
   },
   "outputs": [],
   "source": [
    "class Tacotron2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tacotron2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, model_output, targets):\n",
    "        mel_target, gate_target = targets[0], targets[1]\n",
    "        mel_target.requires_grad = False\n",
    "        gate_target.requires_grad = False\n",
    "        gate_target = gate_target.view(-1, 1)\n",
    "\n",
    "        mel_out, mel_out_postnet, gate_out, _ = model_output\n",
    "        gate_out = gate_out.view(-1, 1)\n",
    "        mel_loss = nn.MSELoss()(mel_out, mel_target) + \\\n",
    "                   nn.MSELoss()(mel_out_postnet, mel_target)\n",
    "        gate_loss = nn.BCEWithLogitsLoss()(gate_out, gate_target)\n",
    "        return mel_loss + gate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6MVOdDz7DMeS"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, learning_rate, iteration, filepath):\n",
    "    print(\"Saving model and optimizer state at iteration {} to {}\".format(\n",
    "        iteration, filepath))\n",
    "    torch.save({'iteration': iteration,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'learning_rate': learning_rate}, filepath)\n",
    "\n",
    "\n",
    "def validate(model, criterion, valset, iteration, batch_size,\n",
    "             collate_fn, distributed_run, rank):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_sampler = DistributedSampler(valset) if distributed_run else None\n",
    "        val_loader = DataLoader(valset, sampler=val_sampler, num_workers=1,\n",
    "                                shuffle=False, batch_size=batch_size,\n",
    "                                pin_memory=False, collate_fn=collate_fn)\n",
    "\n",
    "        val_loss = 0.0\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            x, y = model.parse_batch(batch)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            reduced_val_loss = loss.item()\n",
    "            val_loss += reduced_val_loss\n",
    "        val_loss = val_loss / (i + 1)\n",
    "\n",
    "    model.train()\n",
    "    if rank == 0:\n",
    "        print(\"Validation loss {}: {:9f}  \".format(iteration, val_loss))\n",
    "\n",
    "\n",
    "torch.manual_seed(hparams.seed)\n",
    "torch.cuda.manual_seed(hparams.seed)\n",
    "\n",
    "model = Tacotron2(hparams).cuda()\n",
    "\n",
    "learning_rate = hparams.learning_rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                             weight_decay=hparams.weight_decay)\n",
    "criterion = Tacotron2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzS6Hm14DTmh"
   },
   "source": [
    "### Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5V-HOOT8DbWC"
   },
   "outputs": [],
   "source": [
    "train_loader, valset, collate_fn = prepare_dataloaders(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4SJHtH3dDSIp",
    "outputId": "85447aff-da3b-47a3-a5a9-b15078f3dd62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss 0 6.229181 Grad Norm 8.441121 3.25s/it\n",
      "Validation loss 0:  8.958698  \n",
      "Saving model and optimizer state at iteration 0 to weight/checkpoint_0\n",
      "Train loss 1 6.089982 Grad Norm 7.693520 3.04s/it\n",
      "Train loss 2 6.294034 Grad Norm 6.569690 2.80s/it\n",
      "Train loss 3 5.932669 Grad Norm 6.070018 2.64s/it\n",
      "Train loss 4 6.228306 Grad Norm 5.064931 2.51s/it\n",
      "Train loss 5 5.086986 Grad Norm 2.828938 2.51s/it\n",
      "Train loss 6 5.167689 Grad Norm 2.855681 2.96s/it\n",
      "Train loss 7 4.928387 Grad Norm 2.759265 2.97s/it\n",
      "Train loss 8 4.568196 Grad Norm 2.712311 2.80s/it\n",
      "Train loss 9 5.120548 Grad Norm 3.380471 3.07s/it\n",
      "Train loss 10 5.185434 Grad Norm 2.836573 2.74s/it\n",
      "Train loss 11 4.338415 Grad Norm 3.580614 3.10s/it\n",
      "Train loss 12 4.394618 Grad Norm 2.376952 2.69s/it\n",
      "Train loss 13 5.039035 Grad Norm 3.346883 3.06s/it\n",
      "Train loss 14 4.844556 Grad Norm 2.339330 3.07s/it\n",
      "Train loss 15 4.021041 Grad Norm 3.157732 2.82s/it\n",
      "Train loss 16 4.516615 Grad Norm 2.332708 2.73s/it\n",
      "Train loss 17 4.784995 Grad Norm 2.378166 2.87s/it\n",
      "Train loss 18 3.856616 Grad Norm 2.914753 3.00s/it\n",
      "Train loss 19 4.583630 Grad Norm 2.413519 2.68s/it\n",
      "Train loss 20 3.909870 Grad Norm 3.316780 2.89s/it\n",
      "Train loss 21 3.900133 Grad Norm 1.823784 2.92s/it\n",
      "Train loss 22 3.720907 Grad Norm 5.553056 2.66s/it\n",
      "Train loss 23 5.014612 Grad Norm 5.618773 2.96s/it\n",
      "Train loss 24 4.450815 Grad Norm 3.802830 2.79s/it\n",
      "Train loss 25 4.717663 Grad Norm 4.206950 2.36s/it\n",
      "Train loss 26 4.036412 Grad Norm 5.333710 2.04s/it\n",
      "Train loss 27 4.858854 Grad Norm 6.522015 2.61s/it\n",
      "Train loss 28 3.697910 Grad Norm 2.096571 2.81s/it\n",
      "Train loss 29 4.273714 Grad Norm 1.808062 2.66s/it\n",
      "Train loss 30 4.052767 Grad Norm 5.449198 2.72s/it\n",
      "Train loss 31 3.197776 Grad Norm 1.614371 3.01s/it\n",
      "Train loss 32 4.846284 Grad Norm 8.908648 2.57s/it\n",
      "Train loss 33 3.973189 Grad Norm 7.745533 2.58s/it\n",
      "Train loss 34 3.639272 Grad Norm 1.399399 2.81s/it\n",
      "Train loss 35 4.112069 Grad Norm 9.066121 3.06s/it\n",
      "Train loss 36 3.551771 Grad Norm 6.739942 3.04s/it\n",
      "Train loss 37 3.499899 Grad Norm 1.918910 2.87s/it\n",
      "Train loss 38 3.514270 Grad Norm 4.194751 2.83s/it\n",
      "Train loss 39 3.424102 Grad Norm 2.608065 2.98s/it\n",
      "Train loss 40 3.469117 Grad Norm 7.128908 2.96s/it\n",
      "Train loss 41 3.676008 Grad Norm 8.646382 2.88s/it\n",
      "Train loss 42 3.100527 Grad Norm 1.979373 3.03s/it\n",
      "Train loss 43 2.982695 Grad Norm 5.059516 2.78s/it\n",
      "Train loss 44 3.945414 Grad Norm 10.858052 3.29s/it\n",
      "Train loss 45 3.469772 Grad Norm 5.065967 2.99s/it\n",
      "Train loss 46 3.469114 Grad Norm 3.817281 2.99s/it\n",
      "Train loss 47 3.523878 Grad Norm 6.828208 2.97s/it\n",
      "Train loss 48 4.023506 Grad Norm 2.211846 2.98s/it\n",
      "Train loss 49 3.648723 Grad Norm 3.685698 3.06s/it\n",
      "Train loss 50 3.522075 Grad Norm 3.765283 3.10s/it\n",
      "Train loss 51 3.508873 Grad Norm 2.853925 3.10s/it\n",
      "Train loss 52 3.570788 Grad Norm 4.337198 2.65s/it\n",
      "Train loss 53 4.512183 Grad Norm 6.109277 2.61s/it\n",
      "Train loss 54 3.660959 Grad Norm 4.105080 2.96s/it\n",
      "Train loss 55 3.448289 Grad Norm 5.647274 2.74s/it\n",
      "Train loss 56 3.581472 Grad Norm 4.353257 2.88s/it\n",
      "Train loss 57 2.997391 Grad Norm 1.078934 2.91s/it\n",
      "Train loss 58 3.403714 Grad Norm 6.594098 3.03s/it\n",
      "Train loss 59 3.196304 Grad Norm 6.096474 2.84s/it\n",
      "Train loss 60 2.973942 Grad Norm 1.607712 2.89s/it\n",
      "Train loss 61 3.475065 Grad Norm 6.967393 2.84s/it\n",
      "Train loss 62 3.534863 Grad Norm 9.990738 3.04s/it\n",
      "Train loss 63 3.386340 Grad Norm 4.541806 2.93s/it\n",
      "Train loss 64 3.381036 Grad Norm 5.757030 2.60s/it\n",
      "Train loss 65 3.747736 Grad Norm 7.941907 2.85s/it\n",
      "Train loss 66 3.232586 Grad Norm 3.279889 2.89s/it\n",
      "Train loss 67 3.479201 Grad Norm 3.302529 2.60s/it\n",
      "Train loss 68 3.299989 Grad Norm 5.264028 2.86s/it\n",
      "Train loss 69 3.141108 Grad Norm 2.457431 2.79s/it\n",
      "Train loss 70 3.414630 Grad Norm 6.904702 2.88s/it\n",
      "Train loss 71 5.484570 Grad Norm 15.100968 2.40s/it\n",
      "Train loss 72 3.123376 Grad Norm 4.602531 2.93s/it\n",
      "Train loss 73 3.455316 Grad Norm 6.976435 3.01s/it\n",
      "Train loss 74 3.935638 Grad Norm 10.733862 3.00s/it\n",
      "Train loss 75 3.200159 Grad Norm 4.772754 2.13s/it\n",
      "Train loss 76 2.898151 Grad Norm 1.441607 2.95s/it\n",
      "Train loss 77 3.188280 Grad Norm 6.721539 2.88s/it\n",
      "Train loss 78 3.925906 Grad Norm 9.998693 2.62s/it\n",
      "Train loss 79 3.345031 Grad Norm 1.721709 2.35s/it\n",
      "Train loss 80 3.761841 Grad Norm 10.245427 3.00s/it\n",
      "Train loss 81 3.515119 Grad Norm 10.788863 2.85s/it\n",
      "Train loss 82 3.100986 Grad Norm 6.355798 2.90s/it\n",
      "Train loss 83 2.502356 Grad Norm 1.187331 2.59s/it\n",
      "Train loss 84 3.127834 Grad Norm 8.032939 3.08s/it\n",
      "Train loss 85 3.423621 Grad Norm 10.566456 3.07s/it\n",
      "Train loss 86 4.021348 Grad Norm 13.891246 2.93s/it\n",
      "Train loss 87 3.023965 Grad Norm 2.625453 2.93s/it\n",
      "Train loss 88 3.290028 Grad Norm 11.124676 3.04s/it\n",
      "Train loss 89 3.493453 Grad Norm 13.148634 3.00s/it\n",
      "Train loss 90 3.161603 Grad Norm 8.212774 2.75s/it\n",
      "Train loss 91 2.502208 Grad Norm 1.850058 2.90s/it\n",
      "Train loss 92 3.276206 Grad Norm 8.422445 2.57s/it\n",
      "Train loss 93 3.475292 Grad Norm 9.270916 2.83s/it\n",
      "Train loss 94 3.434855 Grad Norm 6.781613 2.90s/it\n",
      "Train loss 95 2.594929 Grad Norm 2.266084 3.07s/it\n",
      "Train loss 96 2.650103 Grad Norm 6.166852 2.62s/it\n",
      "Train loss 97 2.877972 Grad Norm 4.655624 2.72s/it\n",
      "Train loss 98 2.465895 Grad Norm 1.775347 2.57s/it\n",
      "Train loss 99 3.901753 Grad Norm 7.853387 2.93s/it\n",
      "Train loss 100 3.327626 Grad Norm 6.618919 2.65s/it\n",
      "Validation loss 100:  2.777291  \n",
      "Saving model and optimizer state at iteration 100 to weight/checkpoint_100\n",
      "Train loss 101 2.518504 Grad Norm 4.183763 3.16s/it\n",
      "Train loss 102 2.476815 Grad Norm 1.636901 2.81s/it\n",
      "Train loss 103 2.929969 Grad Norm 6.111385 2.76s/it\n",
      "Train loss 104 2.874550 Grad Norm 3.948234 2.82s/it\n",
      "Train loss 105 2.384548 Grad Norm 3.460467 2.96s/it\n",
      "Train loss 106 2.443566 Grad Norm 3.370929 2.88s/it\n",
      "Train loss 107 2.602071 Grad Norm 3.754665 2.98s/it\n",
      "Train loss 108 2.438863 Grad Norm 2.491391 2.89s/it\n",
      "Train loss 109 2.282102 Grad Norm 3.470712 2.58s/it\n",
      "Train loss 110 2.124534 Grad Norm 2.247614 2.77s/it\n",
      "Train loss 111 2.076037 Grad Norm 3.253735 2.85s/it\n",
      "Train loss 112 2.317055 Grad Norm 4.302967 2.92s/it\n",
      "Train loss 113 2.298854 Grad Norm 3.672926 3.02s/it\n",
      "Train loss 114 2.951082 Grad Norm 3.187992 2.83s/it\n",
      "Train loss 115 2.335906 Grad Norm 4.942580 2.91s/it\n",
      "Train loss 116 2.353564 Grad Norm 3.716464 2.70s/it\n",
      "Train loss 117 2.488826 Grad Norm 5.131991 2.87s/it\n",
      "Train loss 118 2.303131 Grad Norm 3.526244 2.57s/it\n",
      "Train loss 119 2.204989 Grad Norm 3.698455 3.04s/it\n",
      "Train loss 120 2.301412 Grad Norm 2.805861 3.02s/it\n",
      "Train loss 121 2.125594 Grad Norm 1.861407 2.89s/it\n",
      "Train loss 122 2.192083 Grad Norm 2.205281 2.64s/it\n",
      "Train loss 123 2.517113 Grad Norm 3.751011 2.83s/it\n",
      "Train loss 124 2.351158 Grad Norm 3.366093 2.63s/it\n",
      "Train loss 125 2.137203 Grad Norm 2.158809 2.54s/it\n",
      "Train loss 126 2.150863 Grad Norm 3.189471 2.64s/it\n",
      "Train loss 127 2.040954 Grad Norm 1.506238 2.97s/it\n",
      "Train loss 128 2.150841 Grad Norm 5.087818 3.06s/it\n",
      "Train loss 129 3.737167 Grad Norm 4.451869 3.01s/it\n",
      "Train loss 130 2.049836 Grad Norm 3.874048 3.06s/it\n",
      "Train loss 131 2.247174 Grad Norm 2.487010 2.69s/it\n",
      "Train loss 132 2.109917 Grad Norm 5.460225 2.70s/it\n",
      "Train loss 133 2.023412 Grad Norm 2.135248 2.62s/it\n",
      "Train loss 134 1.747566 Grad Norm 2.044780 3.01s/it\n",
      "Train loss 135 1.893399 Grad Norm 3.776195 3.06s/it\n",
      "Train loss 136 3.086288 Grad Norm 6.615710 3.10s/it\n",
      "Train loss 137 3.023698 Grad Norm 5.476359 3.08s/it\n",
      "Train loss 138 2.879504 Grad Norm 5.684660 2.86s/it\n",
      "Train loss 139 2.319870 Grad Norm 3.044638 2.92s/it\n",
      "Train loss 140 2.167146 Grad Norm 2.610511 2.97s/it\n",
      "Train loss 141 2.037789 Grad Norm 3.610826 3.02s/it\n",
      "Train loss 142 1.905602 Grad Norm 4.133098 2.83s/it\n",
      "Train loss 143 1.985317 Grad Norm 2.736777 2.52s/it\n",
      "Train loss 144 2.405875 Grad Norm 4.591055 2.79s/it\n",
      "Train loss 145 2.204496 Grad Norm 2.968365 2.88s/it\n",
      "Train loss 146 2.153167 Grad Norm 3.859900 3.04s/it\n",
      "Train loss 147 2.019604 Grad Norm 1.742037 2.82s/it\n",
      "Train loss 148 2.132975 Grad Norm 2.046428 2.91s/it\n",
      "Train loss 149 2.068299 Grad Norm 2.307036 2.98s/it\n",
      "Train loss 150 2.341206 Grad Norm 4.067758 2.82s/it\n",
      "Train loss 151 2.701364 Grad Norm 5.881693 2.37s/it\n",
      "Train loss 152 2.143206 Grad Norm 5.034833 2.69s/it\n",
      "Train loss 153 2.381964 Grad Norm 6.221762 2.97s/it\n",
      "Train loss 154 2.238501 Grad Norm 2.533468 2.92s/it\n",
      "Train loss 155 1.912765 Grad Norm 2.320817 2.93s/it\n",
      "Train loss 156 2.052302 Grad Norm 2.768098 2.99s/it\n",
      "Train loss 157 1.832774 Grad Norm 4.750473 2.84s/it\n",
      "Train loss 158 1.781496 Grad Norm 3.193998 2.92s/it\n",
      "Train loss 159 2.004623 Grad Norm 4.128978 3.04s/it\n",
      "Train loss 160 2.622670 Grad Norm 8.692843 2.77s/it\n",
      "Train loss 161 2.620241 Grad Norm 5.413493 2.53s/it\n",
      "Train loss 162 2.024006 Grad Norm 10.367732 2.95s/it\n",
      "Train loss 163 2.160977 Grad Norm 11.533848 3.01s/it\n",
      "Train loss 164 2.163513 Grad Norm 7.970164 2.94s/it\n",
      "Train loss 165 2.202532 Grad Norm 2.401489 2.71s/it\n",
      "Train loss 166 1.924220 Grad Norm 3.999458 2.43s/it\n",
      "Train loss 167 2.934749 Grad Norm 6.874395 2.83s/it\n",
      "Train loss 168 2.145391 Grad Norm 4.577103 3.04s/it\n",
      "Train loss 169 2.059309 Grad Norm 4.362309 2.95s/it\n",
      "Train loss 170 1.797275 Grad Norm 2.693567 2.87s/it\n",
      "Train loss 171 2.256201 Grad Norm 4.954210 3.04s/it\n",
      "Train loss 172 1.967877 Grad Norm 5.933445 2.71s/it\n",
      "Train loss 173 1.668096 Grad Norm 1.590092 3.12s/it\n",
      "Train loss 174 3.306054 Grad Norm 5.993088 1.89s/it\n",
      "Train loss 175 2.887581 Grad Norm 6.125156 2.92s/it\n",
      "Train loss 176 1.797129 Grad Norm 3.772674 2.96s/it\n",
      "Train loss 177 2.208084 Grad Norm 3.464146 3.01s/it\n",
      "Train loss 178 1.615760 Grad Norm 2.287976 2.92s/it\n",
      "Train loss 179 2.044867 Grad Norm 3.370393 2.87s/it\n",
      "Train loss 180 2.470512 Grad Norm 2.834908 2.71s/it\n",
      "Train loss 181 1.976450 Grad Norm 6.912721 2.74s/it\n",
      "Train loss 182 2.202202 Grad Norm 5.973464 2.77s/it\n",
      "Train loss 183 2.162571 Grad Norm 3.336089 3.06s/it\n",
      "Train loss 184 2.578755 Grad Norm 7.103380 2.87s/it\n",
      "Train loss 185 2.114868 Grad Norm 2.221947 3.06s/it\n",
      "Train loss 186 1.837318 Grad Norm 4.228772 2.63s/it\n",
      "Train loss 187 1.825127 Grad Norm 5.318716 3.04s/it\n",
      "Train loss 188 1.891376 Grad Norm 1.776305 3.06s/it\n",
      "Train loss 189 2.246332 Grad Norm 1.453127 2.96s/it\n",
      "Train loss 190 2.247947 Grad Norm 3.470479 2.84s/it\n",
      "Train loss 191 2.593791 Grad Norm 3.099107 2.79s/it\n",
      "Train loss 192 2.150420 Grad Norm 8.015577 2.20s/it\n",
      "Train loss 193 2.176377 Grad Norm 3.643787 3.06s/it\n",
      "Train loss 194 2.276917 Grad Norm 5.554086 2.85s/it\n",
      "Train loss 195 2.373549 Grad Norm 7.208960 2.95s/it\n",
      "Train loss 196 2.197549 Grad Norm 4.134211 3.07s/it\n",
      "Train loss 197 1.841724 Grad Norm 5.886121 3.07s/it\n",
      "Train loss 198 2.133305 Grad Norm 7.562266 2.91s/it\n",
      "Train loss 199 2.018549 Grad Norm 3.636955 2.66s/it\n",
      "Train loss 200 2.009282 Grad Norm 4.086936 2.99s/it\n",
      "Validation loss 200:  1.951581  \n",
      "Saving model and optimizer state at iteration 200 to weight/checkpoint_200\n",
      "Train loss 201 1.815910 Grad Norm 5.243608 3.18s/it\n",
      "Train loss 202 1.892019 Grad Norm 3.834227 2.31s/it\n",
      "Train loss 203 2.012856 Grad Norm 2.659512 2.84s/it\n",
      "Train loss 204 1.772073 Grad Norm 4.645777 2.87s/it\n",
      "Train loss 205 1.824784 Grad Norm 1.384752 2.77s/it\n",
      "Train loss 206 1.999868 Grad Norm 4.867511 2.95s/it\n",
      "Train loss 207 2.508264 Grad Norm 7.426137 3.11s/it\n",
      "Train loss 208 1.852420 Grad Norm 1.931535 2.84s/it\n",
      "Train loss 209 2.047628 Grad Norm 4.045258 2.60s/it\n",
      "Train loss 210 1.970243 Grad Norm 5.181418 2.96s/it\n",
      "Train loss 211 1.590490 Grad Norm 2.137861 2.98s/it\n",
      "Train loss 212 2.091710 Grad Norm 5.325807 3.04s/it\n",
      "Train loss 213 1.942797 Grad Norm 5.955375 2.23s/it\n",
      "Train loss 214 2.228698 Grad Norm 4.737135 2.91s/it\n",
      "Train loss 215 1.964849 Grad Norm 7.391150 2.89s/it\n",
      "Train loss 216 1.838972 Grad Norm 6.834856 2.92s/it\n",
      "Train loss 217 2.168317 Grad Norm 4.046550 2.91s/it\n",
      "Train loss 218 2.241405 Grad Norm 5.535276 2.40s/it\n",
      "Train loss 219 2.186849 Grad Norm 6.538924 2.87s/it\n",
      "Train loss 220 1.924077 Grad Norm 2.627127 3.08s/it\n",
      "Train loss 221 2.169887 Grad Norm 4.403897 2.50s/it\n",
      "Train loss 222 2.225773 Grad Norm 4.950499 2.75s/it\n",
      "Train loss 223 1.922485 Grad Norm 3.921183 3.09s/it\n",
      "Train loss 224 1.929777 Grad Norm 4.970788 2.93s/it\n",
      "Train loss 225 2.522274 Grad Norm 9.690495 2.75s/it\n",
      "Train loss 226 2.145378 Grad Norm 5.713562 2.83s/it\n",
      "Train loss 227 1.739434 Grad Norm 2.492558 2.52s/it\n",
      "Train loss 228 1.769308 Grad Norm 2.642181 2.89s/it\n",
      "Train loss 229 1.549158 Grad Norm 1.606087 2.80s/it\n",
      "Train loss 230 2.538054 Grad Norm 9.875828 2.95s/it\n",
      "Train loss 231 2.859683 Grad Norm 11.974735 2.97s/it\n",
      "Train loss 232 2.218882 Grad Norm 6.774609 2.91s/it\n",
      "Train loss 233 2.070240 Grad Norm 2.809086 2.76s/it\n",
      "Train loss 234 2.250055 Grad Norm 6.640979 2.90s/it\n",
      "Train loss 235 1.913835 Grad Norm 6.419417 2.87s/it\n",
      "Train loss 236 1.916732 Grad Norm 3.559466 2.98s/it\n",
      "Train loss 237 2.809637 Grad Norm 8.651695 2.41s/it\n",
      "Train loss 238 2.022195 Grad Norm 5.943856 2.81s/it\n",
      "Train loss 239 1.841480 Grad Norm 3.725761 2.97s/it\n",
      "Train loss 240 2.031296 Grad Norm 2.608676 2.93s/it\n",
      "Train loss 241 1.753907 Grad Norm 4.572778 2.93s/it\n",
      "Train loss 242 1.635958 Grad Norm 2.962175 3.05s/it\n",
      "Train loss 243 1.873308 Grad Norm 3.421372 2.99s/it\n",
      "Train loss 244 1.558210 Grad Norm 1.966726 3.06s/it\n",
      "Train loss 245 1.722055 Grad Norm 3.407662 2.97s/it\n",
      "Train loss 246 2.252843 Grad Norm 1.898461 2.82s/it\n",
      "Train loss 247 2.080009 Grad Norm 7.573859 2.75s/it\n",
      "Train loss 248 2.049210 Grad Norm 7.271040 2.83s/it\n",
      "Train loss 249 2.098922 Grad Norm 4.600351 2.82s/it\n",
      "Train loss 250 1.698236 Grad Norm 2.791189 2.94s/it\n",
      "Train loss 251 2.251430 Grad Norm 8.223186 2.61s/it\n",
      "Train loss 252 1.991349 Grad Norm 4.661998 3.02s/it\n",
      "Train loss 253 1.822483 Grad Norm 2.312268 3.07s/it\n",
      "Train loss 254 2.154560 Grad Norm 1.227899 2.67s/it\n",
      "Train loss 255 1.851817 Grad Norm 4.751972 2.86s/it\n",
      "Train loss 256 1.898083 Grad Norm 4.488482 2.67s/it\n",
      "Train loss 257 2.020912 Grad Norm 3.001440 3.01s/it\n",
      "Train loss 258 2.675902 Grad Norm 7.897017 2.89s/it\n",
      "Train loss 259 1.628629 Grad Norm 2.584410 2.88s/it\n",
      "Train loss 260 2.014791 Grad Norm 2.634058 3.08s/it\n",
      "Train loss 261 1.841569 Grad Norm 2.303751 2.44s/it\n",
      "Train loss 262 2.007215 Grad Norm 2.738608 3.08s/it\n",
      "Train loss 263 1.887887 Grad Norm 2.322770 2.49s/it\n",
      "Train loss 264 1.864058 Grad Norm 2.554779 2.60s/it\n",
      "Train loss 265 1.628387 Grad Norm 2.155075 2.83s/it\n",
      "Train loss 266 2.112748 Grad Norm 2.404964 2.88s/it\n",
      "Train loss 267 1.850020 Grad Norm 1.596882 2.84s/it\n",
      "Train loss 268 1.719670 Grad Norm 2.975082 3.05s/it\n",
      "Train loss 269 1.962327 Grad Norm 2.125626 2.99s/it\n",
      "Train loss 270 1.729103 Grad Norm 3.216182 2.96s/it\n",
      "Train loss 271 1.524880 Grad Norm 3.115180 3.02s/it\n",
      "Train loss 272 1.992559 Grad Norm 2.655164 3.03s/it\n",
      "Train loss 273 1.870700 Grad Norm 3.922664 3.05s/it\n",
      "Train loss 274 2.146532 Grad Norm 2.712884 2.88s/it\n",
      "Train loss 275 1.952717 Grad Norm 2.910739 2.88s/it\n",
      "Train loss 276 1.875890 Grad Norm 2.372166 2.64s/it\n",
      "Train loss 277 1.820325 Grad Norm 1.849328 2.63s/it\n",
      "Train loss 278 1.820757 Grad Norm 3.569221 2.76s/it\n",
      "Train loss 279 1.922433 Grad Norm 3.507413 3.04s/it\n",
      "Train loss 280 1.825462 Grad Norm 1.805065 2.61s/it\n",
      "Train loss 281 2.005316 Grad Norm 3.317729 2.93s/it\n",
      "Train loss 282 1.911991 Grad Norm 2.205484 3.09s/it\n",
      "Train loss 283 1.648524 Grad Norm 3.290517 3.00s/it\n",
      "Train loss 284 1.675383 Grad Norm 3.191962 2.98s/it\n",
      "Train loss 285 1.638458 Grad Norm 1.313934 2.94s/it\n",
      "Train loss 286 2.001659 Grad Norm 6.160471 2.80s/it\n",
      "Train loss 287 2.177470 Grad Norm 8.379801 2.96s/it\n",
      "Train loss 288 1.870481 Grad Norm 4.164294 2.97s/it\n",
      "Train loss 289 1.836182 Grad Norm 4.069310 2.68s/it\n",
      "Train loss 290 1.639520 Grad Norm 5.061209 2.27s/it\n",
      "Train loss 291 1.793169 Grad Norm 3.286309 3.11s/it\n",
      "Train loss 292 1.941395 Grad Norm 2.304774 2.80s/it\n",
      "Train loss 293 1.765769 Grad Norm 4.392940 3.06s/it\n",
      "Train loss 294 1.777244 Grad Norm 1.769531 3.06s/it\n",
      "Train loss 295 2.009700 Grad Norm 4.296770 2.92s/it\n",
      "Train loss 296 1.817163 Grad Norm 3.327689 3.00s/it\n",
      "Train loss 297 2.068033 Grad Norm 2.195457 2.90s/it\n",
      "Train loss 298 1.946542 Grad Norm 5.804541 2.94s/it\n",
      "Train loss 299 1.636274 Grad Norm 6.992383 3.05s/it\n",
      "Train loss 300 2.073824 Grad Norm 4.084623 2.72s/it\n",
      "Validation loss 300:  1.706656  \n",
      "Saving model and optimizer state at iteration 300 to weight/checkpoint_300\n",
      "Train loss 301 2.080250 Grad Norm 3.731173 3.07s/it\n",
      "Train loss 302 2.247157 Grad Norm 6.770458 2.68s/it\n",
      "Train loss 303 1.648139 Grad Norm 1.481651 2.62s/it\n",
      "Train loss 304 1.883925 Grad Norm 2.022064 2.78s/it\n",
      "Train loss 305 1.596346 Grad Norm 3.714657 3.01s/it\n",
      "Train loss 306 1.766455 Grad Norm 1.368672 2.93s/it\n",
      "Train loss 307 1.600120 Grad Norm 2.605226 2.99s/it\n",
      "Train loss 308 1.725498 Grad Norm 3.130663 2.92s/it\n",
      "Train loss 309 1.410074 Grad Norm 1.728318 2.74s/it\n",
      "Train loss 310 1.986973 Grad Norm 2.401006 2.81s/it\n",
      "Train loss 311 1.834012 Grad Norm 0.919534 2.98s/it\n",
      "Train loss 312 1.801703 Grad Norm 1.919496 2.68s/it\n",
      "Train loss 313 1.738568 Grad Norm 2.082886 2.65s/it\n",
      "Train loss 314 1.469484 Grad Norm 3.013731 2.40s/it\n",
      "Train loss 315 1.964448 Grad Norm 2.244637 3.02s/it\n",
      "Train loss 316 1.996807 Grad Norm 3.223428 2.82s/it\n",
      "Train loss 317 1.950881 Grad Norm 1.681198 2.76s/it\n",
      "Train loss 318 1.957565 Grad Norm 2.238664 2.73s/it\n",
      "Train loss 319 1.923971 Grad Norm 2.409796 2.88s/it\n",
      "Train loss 320 1.862843 Grad Norm 1.596477 2.18s/it\n",
      "Train loss 321 1.666337 Grad Norm 2.297060 3.22s/it\n",
      "Train loss 322 1.752594 Grad Norm 1.508889 3.11s/it\n",
      "Train loss 323 2.127304 Grad Norm 6.893904 2.73s/it\n",
      "Train loss 324 1.891685 Grad Norm 5.661624 2.97s/it\n",
      "Train loss 325 1.973938 Grad Norm 1.886283 2.73s/it\n",
      "Train loss 326 1.377827 Grad Norm 2.379029 3.12s/it\n",
      "Train loss 327 1.637878 Grad Norm 2.110407 3.00s/it\n",
      "Train loss 328 1.997003 Grad Norm 2.577734 2.98s/it\n",
      "Train loss 329 1.706236 Grad Norm 1.555259 2.53s/it\n",
      "Train loss 330 1.813603 Grad Norm 4.724315 2.99s/it\n",
      "Train loss 331 1.986963 Grad Norm 3.211351 3.00s/it\n",
      "Train loss 332 1.850784 Grad Norm 2.164324 2.77s/it\n",
      "Train loss 333 1.288930 Grad Norm 1.865840 2.85s/it\n",
      "Train loss 334 1.976851 Grad Norm 1.285118 2.83s/it\n",
      "Train loss 335 1.704194 Grad Norm 3.252601 2.99s/it\n",
      "Train loss 336 1.406086 Grad Norm 2.060239 2.98s/it\n",
      "Train loss 337 2.011918 Grad Norm 3.025868 3.01s/it\n",
      "Train loss 338 1.609751 Grad Norm 2.157809 2.93s/it\n",
      "Train loss 339 1.851683 Grad Norm 2.730339 2.58s/it\n",
      "Train loss 340 1.538836 Grad Norm 2.139246 2.70s/it\n",
      "Train loss 341 1.578616 Grad Norm 2.219556 2.91s/it\n",
      "Train loss 342 1.782422 Grad Norm 2.667225 3.05s/it\n",
      "Train loss 343 1.433208 Grad Norm 1.139776 2.93s/it\n",
      "Train loss 344 1.611538 Grad Norm 3.923878 2.77s/it\n",
      "Train loss 345 1.641574 Grad Norm 2.377758 2.60s/it\n",
      "Train loss 346 1.974670 Grad Norm 5.752795 3.02s/it\n",
      "Train loss 347 1.712489 Grad Norm 4.753448 3.05s/it\n",
      "Train loss 348 1.898414 Grad Norm 2.000967 2.65s/it\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0be40313ca05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreduced_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         grad_norm = torch.nn.utils.clip_grad_norm_(\n\u001b[1;32m     22\u001b[0m             model.parameters(), hparams.grad_clip_thresh)\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('weight'):\n",
    "  os.mkdir('weight')\n",
    "  \n",
    "model.train()\n",
    "is_overflow = False\n",
    "iteration = 0\n",
    "# ================ MAIN TRAINNIG LOOP! ===================\n",
    "for epoch in range(0, hparams.epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        start = time.perf_counter()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "        model.zero_grad()\n",
    "        x, y = model.parse_batch(batch)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        reduced_loss = loss.item()\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), hparams.grad_clip_thresh)\n",
    "        optimizer.step()\n",
    "        if not is_overflow:\n",
    "            duration = time.perf_counter() - start\n",
    "            print(\"Train loss {} {:.6f} Grad Norm {:.6f} {:.2f}s/it\".format(\n",
    "                iteration, reduced_loss, grad_norm, duration))\n",
    "\n",
    "        if not is_overflow and (iteration % hparams.iters_per_checkpoint == 0):\n",
    "            validate(model, criterion, valset, iteration,\n",
    "                     hparams.batch_size, collate_fn,\n",
    "                     hparams.distributed_run, 0)\n",
    "            checkpoint_path = os.path.join(\n",
    "                \"weight\", \"checkpoint_{}\".format(iteration))\n",
    "            save_checkpoint(model, optimizer, learning_rate, iteration,\n",
    "                            checkpoint_path)\n",
    "        iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFwk-0VqDSLc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QvYf6sLDSN3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "13_Seq2Seq_Text2Speech.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
